{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import networkx as nx\n",
    "import sqlite3 as s3\n",
    "from datetime import datetime, timedelta\n",
    "import gzip\n",
    "from copy import deepcopy\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = s3.connect('CTROT')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building retweets database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Go through files with tweets of any kind and load the basic data into a large table\n",
    "path = os.getcwd()+\"/us_wn_timelines/\"       #This assumes a folder of folders of data\n",
    "\n",
    "#Create tables\n",
    "#User that retweeted, user that was retweeted, number of times this happened for that date, other data?\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS retweets\n",
    "            (created_at DATE, retweeter text, retweeted text)''')\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS user_info\n",
    "            (id int, name text, followers_count int)''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #for foldered files\n",
    "# for folder in os.listdir(path):\n",
    "#     print folder\n",
    "#     for filename in tqdm(os.listdir(path+folder)):\n",
    "#         #user = filename.split(\".\")[0]\n",
    "#         with open(path+folder+\"/\"+filename,'r') as f:\n",
    "#             retweets = []\n",
    "#             id_info = []\n",
    "#             for line in f:\n",
    "#                 doc = json.loads(line.replace(\",\\n\",\"\"))\n",
    "#                 if 'retweeted_status' in doc:\n",
    "#                     #Write retweet instances into table of retweets\n",
    "#                     d = datetime.strptime(doc['created_at'],'%a %b %d %H:%M:%S +0000 %Y')\n",
    "#                     t = datetime(d.year,d.month,d.day)\n",
    "#                     retweets.append((t, doc['user']['id'], doc['retweeted_status']['user']['id']))\n",
    "#                     #Write IDs into table of user information\n",
    "#                     #id_info.append((doc['user']['id'], doc['user']['name'], doc['user']['followers_count']))\n",
    "#             #Maybe send it to the server in batches later\n",
    "#             c.executemany('INSERT INTO retweets VALUES (?,?,?)', retweets)\n",
    "#             #c.executemany('INSERT INTO user_info VALUES (?,?,?)', id_info)\n",
    "#         conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "873it [00:00, 8726.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5708628it [07:08, 13330.20it/s]\n",
      "420it [00:00, 4199.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_af.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6090555it [07:49, 12964.20it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bk.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1964748it [02:24, 13614.13it/s]\n",
      "1149it [00:00, 11486.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_seeds.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81858it [00:05, 16283.77it/s]\n",
      "150it [00:00, 1499.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ad.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5930377it [07:17, 13565.15it/s]\n",
      "1it [00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bd.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5553330it [06:50, 13525.38it/s]\n",
      "1it [00:00,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_as.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5863730it [07:13, 13519.28it/s]\n",
      "1it [00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ab.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6198640it [07:29, 13775.14it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_al.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5760687it [07:11, 13352.29it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ay.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5931366it [07:15, 13622.78it/s]\n",
      "1it [00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bj.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5697843it [06:54, 13760.51it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_aa.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6016969it [07:16, 13780.85it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bc.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5777207it [06:58, 13793.27it/s]\n",
      "1it [00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_az.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5739370it [06:49, 13999.37it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ax.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5714836it [06:53, 13814.46it/s]\n",
      "855it [00:00, 8547.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ap.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5888642it [07:00, 13989.58it/s]\n",
      "721it [00:00, 7208.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ba.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5703544it [06:53, 13779.78it/s]\n",
      "125it [00:00, 1248.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bb.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5483742it [06:36, 13818.60it/s]\n",
      "1it [00:00,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ae.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5878863it [07:01, 13932.86it/s]\n",
      "1it [00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ag.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5990278it [07:06, 14038.81it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_am.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5683760it [06:45, 14011.39it/s]\n",
      "680it [00:00, 6799.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bh.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5744275it [06:49, 14023.90it/s]\n",
      "708it [00:00, 7079.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bi.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5775447it [06:59, 13774.34it/s]\n",
      "8it [00:00, 79.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ak.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5724378it [06:51, 13898.80it/s]\n",
      "562it [00:00, 5616.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ah.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5729958it [06:55, 13794.85it/s]\n",
      "37it [00:00, 369.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_aq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5612964it [06:47, 13767.35it/s]\n",
      "1it [00:00,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_au.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5787133it [06:54, 13950.36it/s]\n",
      "1it [00:00,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_be.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5798789it [06:58, 13865.36it/s]\n",
      "289it [00:00, 2887.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_at.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5826789it [07:01, 13831.97it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_bf.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5507526it [06:35, 13941.90it/s]\n",
      "132it [00:00, 1318.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_an.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5793044it [06:57, 13876.90it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_av.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5751087it [06:53, 13898.92it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ai.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5813499it [06:56, 13948.78it/s]\n",
      "2it [00:00, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_ac.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5983293it [07:35, 13136.72it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_aj.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5709151it [07:18, 13005.00it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_us_wn_1degree_followers_unique_aw.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5834156it [07:18, 13311.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#for gzipped files\n",
    "for f_gz in (thing for thing in os.listdir(path) if thing.endswith(\".gz\")):\n",
    "    print f_gz\n",
    "    with gzip.open(path+\"/\"+f_gz,'r') as f:\n",
    "        retweets = []\n",
    "        id_info = []\n",
    "        for line in tqdm(f):\n",
    "            if line==\"\\n\":\n",
    "                continue\n",
    "            else:\n",
    "                doc = json.loads(line.replace(\",\\n\",\"\"))\n",
    "                user = doc['user']['id']\n",
    "                if 'retweeted_status' in doc:\n",
    "                    #Write retweet instances into table of retweets\n",
    "                    d = datetime.strptime(doc['created_at'],'%a %b %d %H:%M:%S +0000 %Y')\n",
    "                    t = datetime(d.year,d.month,d.day)\n",
    "                    retweets.append((t, doc['user']['id'], doc['retweeted_status']['user']['id']))\n",
    "        c.executemany('INSERT INTO retweets VALUES (?,?,?)', retweets)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f1c2a26fb90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index the retweet table by date\n",
    "c.execute(\"CREATE INDEX date_index ON retweets (created_at);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building k_values database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use network code that queries the database by day to build the network over time\n",
    "bin_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Have this network output k-values into another giant table with:\n",
    "    #User, date, k-value\n",
    "    \n",
    "#Table\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS k_values2\n",
    "             (user text, date DATE, k_value int)''')\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS normalized_k2\n",
    "             (user text, date DATE, k_value int)''')\n",
    "\n",
    "#Date handling\n",
    "#Get the earliest date in the data\n",
    "c.execute(\"SELECT * FROM retweets ORDER BY date(created_at) ASC Limit 1\")\n",
    "current_date = datetime.strptime(c.fetchall()[0][0],\"%Y-%m-%d 00:00:00\") \n",
    "#Get the final date in the data\n",
    "c.execute(\"SELECT * FROM retweets ORDER BY date(created_at) DESC Limit 1\")\n",
    "end_date = datetime.strptime(c.fetchall()[0][0],\"%Y-%m-%d 00:00:00\")\n",
    "total_days = end_date - current_date\n",
    "total_days = total_days.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2743 of 2924"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ec73bbc9e5cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM retweets WHERE created_at='\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcurrent_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d 00:00:00\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"'\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0malready_did\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Making sure you're only keeping track of whether retweeted that day\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#instance := (date, user that retweeted, original user of tweet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malready_did\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nextdoc = True\n",
    "\n",
    "#Graph\n",
    "g = nx.Graph()\n",
    "\n",
    "while nextdoc: #For each date\n",
    "    #Add nodes into the network\n",
    "    c.execute(\"SELECT * FROM retweets WHERE created_at='\"+current_date.strftime(\"%Y-%m-%d 00:00:00\")+\"'\" )\n",
    "    already_did = set() #Making sure you're only keeping track of whether retweeted that day\n",
    "    for user in c.fetchall():\n",
    "        #instance := (date, user that retweeted, original user of tweet)\n",
    "        if g.has_edge(user[1],user[2]) and (user[1],user[2]) not in already_did:\n",
    "            g[user[1]][user[2]]['weight']=7\n",
    "            already_did.add((user[1],user[2]))\n",
    "        else:\n",
    "            g.add_edge(user[1],user[2],weight=7)\n",
    "            already_did.add((user[1],user[2]))\n",
    "    \n",
    "    #Remove nodes from the network\n",
    "    backdate = current_date - timedelta(days=bin_size)\n",
    "    c.execute(\"SELECT * FROM retweets WHERE created_at='\"+backdate.strftime(\"%Y-%m-%d 00:00:00\")+\"'\")\n",
    "    for user in c.fetchall():\n",
    "        #Pruning\n",
    "        if g.has_edge(user[1],user[2]) and (user[1],user[2]) not in already_did: \n",
    "            g[user[1]][user[2]]['weight'] -= 1\n",
    "            already_did.add((user[1],user[2]))\n",
    "        if g.has_edge(user[1],user[2]) and g[user[1]][user[2]]['weight']==0:\n",
    "            g.remove_edge(user[1],user[2])\n",
    "    \n",
    "    #Remove isolates, self-loops\n",
    "    isolates = [x for x in nx.isolates(g)]\n",
    "    g.remove_nodes_from(isolates)\n",
    "    g.remove_edges_from(g.selfloop_edges())\n",
    "    \n",
    "    #Export out the current network\n",
    "    k_values_doc = nx.core_number(g)\n",
    "    k_values = [(user,current_date,k_values_doc[user]) for user in k_values_doc]\n",
    "    c.executemany('INSERT INTO k_values2 VALUES (?,?,?)', k_values)\n",
    "    \n",
    "    #Handle normalization\n",
    "    g_norm = nx.Graph(g)\n",
    "    if nx.number_of_nodes(g_norm)>4:\n",
    "        g_norm = nx.double_edge_swap(g_norm, nswap=2*nx.number_of_nodes(g_norm), max_tries=float(\"inf\"))\n",
    "    k_values_doc = nx.core_number(g_norm)\n",
    "    k_values = [(user,current_date,k_values_doc[user]) for user in k_values_doc]\n",
    "    c.executemany('INSERT INTO normalized_k2 VALUES (?,?,?)', k_values)\n",
    "    \n",
    "    #update current date\n",
    "    current_date += timedelta(days=1)\n",
    "    if current_date == end_date:\n",
    "        nextdoc = False\n",
    "        break\n",
    "    \n",
    "    #Output for human eyes only\n",
    "    daydiff = end_date - current_date\n",
    "    sys.stdout.write(\"\\r%i of %i\"%((total_days - daydiff.days),total_days-1))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#Commit to database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "index user_index already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c8cfb530192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#index the table by user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE INDEX user_index ON k_values2 (user);\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: index user_index already exists"
     ]
    }
   ],
   "source": [
    "#index the table by user\n",
    "c.execute(\"CREATE INDEX user_index ON k_values2 (user);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: main.renormalized_k2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8cbc6740e363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#index the table by date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE INDEX date_index ON renormalized_k2 (date);\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: main.renormalized_k2"
     ]
    }
   ],
   "source": [
    "#index the table by date\n",
    "c.execute(\"CREATE INDEX date_index ON renormalized_k2 (date);\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
