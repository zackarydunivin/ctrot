{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community as comm1\n",
    "import community as comm2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict #Used to transpose dictionary\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networks_folder = \"networks_folder/\"\n",
    "nodestats_folder = \"nodestats_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_nodes = [27522964, 42786325, 52352820, 72931184, 75736238, 87229781, 90657826, 114374226, 152852932, 154891961, 209693451, 271397818, 322027737, 402181258, 433462889, 1457805708, 2167525794, 2231109295, 2349347329, 2442888666, 2490088512, 2888660047, 2915187060, 2995401932, 3012158891, 3234613430, 3999537573, 813914393788481540, 817163123182465024, 832319306541178881, 850408392925499392, 857482409012547584, 894682675893735426, 903046544919732224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(networks_folder+'2013-09-07_reg.pickle','rb') as f:\n",
    "    g = pickle.load(f)\n",
    "#Making iGraph, because networkx doesn't have good native community detection\n",
    "g_ig_lookup_table = {}\n",
    "counter = 0\n",
    "for node in g:\n",
    "    g_ig_lookup_table[node] = counter\n",
    "    counter += 1\n",
    "g_ig = ig.Graph(len(g), [(g_ig_lookup_table[x],g_ig_lookup_table[y]) for x,y in list(g.edges()) if y!='None'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics of interest\n",
    "* Shortest path to seeds\n",
    "* Distribution of people in k-shells over time\n",
    "* Communities and their membership over time\n",
    "* Figure out centrality distribution for evenness. Are bots really high?\n",
    "\n",
    "Use LaNet-Vi to visualize k-core\n",
    "How do check for number of overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node statistics - Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortestPath2Seeds(source_seed,seed_nodes,g):\n",
    "    test_minimum_path = []\n",
    "    #Remove edges from seed nodes\n",
    "    seed_nodes_in_graph = [x for x in seed_nodes if x in g]\n",
    "    for remaining_seed in seed_nodes_in_graph:\n",
    "        removed_seed_edges = g.edges([x for x in seed_nodes if x!= remaining_seed])\n",
    "        h = nx.DiGraph(g)\n",
    "        h.remove_edges_from(removed_seed_edges)\n",
    "        if remaining_seed in h and nx.has_path(h,source_seed,remaining_seed):\n",
    "            test_minimum_path.append( len(nx.shortest_path(h,source_seed,remaining_seed)) )\n",
    "        #g.add_edges_from(removed_seed_edges)\n",
    "    if test_minimum_path==[]:\n",
    "        return -1\n",
    "    else: \n",
    "        return min(test_minimum_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#k_core values\n",
    "k_core = nx.core_number(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_paths_2_seeds = {}\n",
    "for node in tqdm(g):\n",
    "    shortest_paths_2_seeds[node] = shortestPath2Seeds(node,seed_nodes,g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running this for all networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in tqdm(os.listdir(networks_folder)):\n",
    "    with open(networks_folder+filename) as f:\n",
    "        g = pickle.load(f)\n",
    "    k_core = nx.core_number(g)\n",
    "    shortest_paths_2_seeds = {}\n",
    "    for node in tqdm(g):\n",
    "        shortest_paths_2_seeds[node] = shortestPath2Seeds(node,seed_nodes,g)\n",
    "    df = pd.DataFrame([k_core,shortest_paths_2_seeds])\n",
    "    \n",
    "#     with open(nodestats_folder+filename) as f:\n",
    "#         df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection - Single\n",
    "\n",
    "In this section, I'm going evaluate the communities on the dynamic RT/MN networks to track the emergence and evolution of communities in the network. \n",
    "\n",
    "I implement the _consensus clustering_ method outlined in Lancichinetti & Fortunato's paper (2012) with application to dynamic networks as outlined in Fortunato (2016). Consensus clustering is basically running many community detection methods and then weighting the edges of the network with the mutual pairs in each community detection result. Then run a weighted community detection method on the weighted graph. For the dynamic networks, I'm going to use the Hungarian algorithm for the assignment problem of matching communities across moving bins that minimize the Jaccard distances between community membership. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                 | My ideas      | Learned from Santo |\n",
    "|-----------------|---------------|--------------------|\n",
    "| Partition Type  | Community     | Cover              |\n",
    "| Distance metric | Jaccard D     | NMI                |\n",
    "| Assignment Alg  | Min Hungarian | Pick best?         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic parameters\n",
    "g_consensus_cluster = nx.Graph(g)\n",
    "#Add edge attributes\n",
    "nx.set_edge_attributes(g_consensus_cluster,name='weight',values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual community assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transposeDict(original_dict,items=False):\n",
    "    result = defaultdict(list)\n",
    "    items_l = original_dict.items() if not items else original_dict\n",
    "    for k,v in items_l:\n",
    "        result[v].append(k)\n",
    "    result = dict(result)\n",
    "    return result\n",
    "\n",
    "def incrementWeights(partition_transpose,g_temp,is_ig=False): #CHANGE THIS TO ACTUALLY BE RIGHT\n",
    "    if is_ig:\n",
    "        g_ig_lookup_table_rev = transposeDict(g_ig_lookup_table)\n",
    "        for thing in partition_transpose:\n",
    "            partition_transpose[thing] = set([g_ig_lookup_table_rev[x][0] for x in partition_transpose[thing]])\n",
    "    for comm in partition_transpose:\n",
    "        for e1,e2 in combinations(partition_transpose[comm],2):\n",
    "            if g_temp.has_edge(e1,e2):\n",
    "                g_temp[e1][e2]['weight'] += 1\n",
    "#             else:\n",
    "#                 g.add_edge(e1,e2,attr_dict={'weight':1})\n",
    "    return g_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Communities over time - Using consensus clustering\n",
    "#Louvain community\n",
    "partition_lou = comm2.best_partition(nx.Graph(g))\n",
    "partition_lou_transpose = transposeDict(partition_lou)\n",
    "#Push to original graph\n",
    "g_consensus_cluster = incrementWeights(partition_lou_transpose,g_consensus_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infomap\n",
    "partition_info = g_ig.community_infomap(trials=20)\n",
    "partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_info.membership)\n",
    "partition_info_transpose = transposeDict(partition_memberships,items=True)\n",
    "#Push to original graph\n",
    "g_consensus_cluster = incrementWeights(partition_info_transpose,g_consensus_cluster,is_ig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Label propogation method\n",
    "#comm1.label_propagation_communities(g) #networkx implementation, doesn't seem to work\n",
    "partition_label = g_ig.community_label_propagation()\n",
    "partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_label.membership)\n",
    "partition_label_transpose = transposeDict(partition_memberships,items=True)\n",
    "#Push to original graph\n",
    "g_consensus_cluster = incrementWeights(partition_label_transpose,g_consensus_cluster,is_ig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consensus cluster community assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Louvain\n",
    "partition_f = comm2.best_partition(g_consensus_cluster)\n",
    "partition_f_transpose = transposeDict(partition_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling dynamic communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hungarian import Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"partition_delta.pickle\") as f:\n",
    "    partitions_over_time = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_part = partitions_over_time[0]#Start with the first one in the time series\n",
    "\n",
    "for next_part in tqdm(partitions_over_time[1:]):\n",
    "    jacmatrix = np.zeros((len(prev_part),len(next_part)))\n",
    "    for i,x in enumerate(prev_part.keys()):\n",
    "        for j,y in enumerate(next_part.keys()):\n",
    "            one = set(prev_part[x])\n",
    "            two = set(next_part[y])\n",
    "            jacmatrix[i][j] = 1 - len(one|two)/len(one&two)\n",
    "    #Computer matrix of Jaccard distances between communities\n",
    "    #Hungarian from prev to next (forward)\n",
    "    hungarian = Hungarian(jacmatrix)\n",
    "    hungarian.calculate()\n",
    "    forward_map = hungarian.get_results()\n",
    "    #Hungarian from next to prev (backward)\n",
    "    hungarian2 = Hungarian(np.transpose(jacmatrix))\n",
    "    hungarian.calculate()\n",
    "    backward_map = hungarian.get_results()\n",
    "    \n",
    "    valid_partitions = [pair for pair in forward_map if pair in backward_map or pair[::-1] in backward_map]\n",
    "    #Relabel based on these results\n",
    "    #The rest of the communities with no best match:\n",
    "        #Create a new label for them\n",
    "    prev_part = next_part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
