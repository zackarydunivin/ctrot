{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel implementation of \"Analyzing networks\" notebook\n",
    "\n",
    "Like my other notebooks, this is a testing and staging notebook for a future python script. \n",
    "\n",
    "This script  will run all of the community detection methods on the networks in parallel and output the list of partitions into a pickled file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community as comm1\n",
    "import community as comm2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from collections import defaultdict #Used to transpose dictionary\n",
    "from itertools import combinations\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networks_folder = \"networks_folder/\"\n",
    "nodestats_folder = \"nodestats_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_nodes = [27522964, 42786325, 52352820, 72931184, 75736238, 87229781, 90657826, 114374226, 152852932, 154891961, 209693451, 271397818, 322027737, 402181258, 433462889, 1457805708, 2167525794, 2231109295, 2349347329, 2442888666, 2490088512, 2888660047, 2915187060, 2995401932, 3012158891, 3234613430, 3999537573, 813914393788481540, 817163123182465024, 832319306541178881, 850408392925499392, 857482409012547584, 894682675893735426, 903046544919732224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics of interest\n",
    "* Shortest path to seeds\n",
    "* Distribution of people in k-shells over time\n",
    "* Communities and their membership over time\n",
    "* Figure out centrality distribution for evenness. Are bots really high?\n",
    "\n",
    "Use LaNet-Vi to visualize k-core\n",
    "How do check for number of overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortestPath2Seeds(source_seed,seed_nodes,g):\n",
    "    test_minimum_path = []\n",
    "    #Remove edges from seed nodes\n",
    "    seed_nodes_in_graph = [x for x in seed_nodes if x in g]\n",
    "    if len(seed_nodes_in_graph)==0:\n",
    "        return -2\n",
    "    for remaining_seed in seed_nodes_in_graph:\n",
    "        removed_seed_edges = g.edges([x for x in seed_nodes if x!= remaining_seed])\n",
    "        h = nx.DiGraph(g)\n",
    "        h.remove_edges_from(removed_seed_edges)\n",
    "        if remaining_seed in h and nx.has_path(h,source_seed,remaining_seed):\n",
    "            test_minimum_path.append( len(nx.shortest_path(h,source_seed,remaining_seed)) )\n",
    "        #g.add_edges_from(removed_seed_edges)\n",
    "    if test_minimum_path==[]:\n",
    "        return -1\n",
    "    else: \n",
    "        return min(test_minimum_path)\n",
    "    \n",
    "def transposeDict(original_dict,items=False):\n",
    "    result = defaultdict(list)\n",
    "    items_l = original_dict.items() if not items else original_dict\n",
    "    for k,v in items_l:\n",
    "        result[v].append(k)\n",
    "    result = dict(result)\n",
    "    return result\n",
    "\n",
    "def incrementWeights(partition_transpose,g_temp):\n",
    "    for comm in partition_transpose:\n",
    "        for e1,e2 in combinations(partition_transpose[comm],2):\n",
    "            if g_temp.has_edge(e1,e2):\n",
    "                g_temp[e1][e2]['weight'] += 1\n",
    "    return g_temp\n",
    "\n",
    "def incrementAdjacency(partition_transpose, adj_dict):\n",
    "    for comm in partition_transpose:\n",
    "        for e1,e2 in combinations(partition_transpose[comm],2):\n",
    "            if (e1,e2) not in adj_dict:\n",
    "                adj_dict[(e1,e2)] = 0\n",
    "            adj_dict[(e1,e2)] += 1\n",
    "    return adj_dict\n",
    "\n",
    "def savedf(df):\n",
    "    with open(nodestats_folder+filename,'w') as f:\n",
    "        df.to_csv()\n",
    "    print(\"%s finished!\"%filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def networkCalc(filename):\n",
    "    print(\"%s started...\"%filename)\n",
    "    with open(networks_folder+filename,'rb') as f:\n",
    "        g = pickle.load(f)\n",
    "    print(\"Calculating k-core\")\n",
    "    k_core = nx.core_number(g)\n",
    "#     shortest_paths_2_seeds = {}\n",
    "#     for node in tqdm(g):\n",
    "#         shortest_paths_2_seeds[node] = shortestPath2Seeds(node,seed_nodes,g)\n",
    "    \n",
    "    print(\"Creating igraph\")\n",
    "    #Creating igraph\n",
    "    g_ig_lookup_table = {}\n",
    "    counter = 0\n",
    "    for node in g:\n",
    "        g_ig_lookup_table[node] = counter\n",
    "        counter += 1\n",
    "    g_ig = ig.Graph(len(g), [(g_ig_lookup_table[x],g_ig_lookup_table[y]) for x,y in list(g.edges()) if y!='None'])\n",
    "    g_ig_lookup_table_rev = transposeDict(g_ig_lookup_table)\n",
    "    \n",
    "    print(\"Creating consensus cluster\")\n",
    "    #Creating consensus cluster\n",
    "    g_consensus_cluster = nx.Graph(g)\n",
    "    nx.set_edge_attributes(g_consensus_cluster,name='weight',values=0)\n",
    "    #Creating consensus matrix\n",
    "    adj_dict = {}\n",
    "    \n",
    "    print(\"Louvain...\")\n",
    "    #Communities over time - Using consensus clustering\n",
    "    #Louvain community\n",
    "    partition_lou = comm2.best_partition(nx.Graph(g))\n",
    "    partition_lou_transpose = transposeDict(partition_lou)\n",
    "    print(\"Pushing\")\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_lou_transpose,g_consensus_cluster)\n",
    "    adj_dict = incrementAdjacency(partition_lou_transpose,adj_dict)\n",
    "\n",
    "    print(\"Infomap...\")\n",
    "    #Infomap\n",
    "    partition_info = g_ig.community_infomap(trials=20)\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_info.membership)\n",
    "    partition_info_transpose = transposeDict(partition_memberships,items=True)\n",
    "    partition_info_transpose_relabel = {}\n",
    "    for thing in partition_info_transpose:\n",
    "        partition_info_transpose_relabel[thing] = set([g_ig_lookup_table_rev[x][0] for x in partition_info_transpose[thing]])\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_info_transpose_relabel,g_consensus_cluster)\n",
    "    adj_dict = incrementAdjacency(partition_info_transpose_relabel,adj_dict)\n",
    "\n",
    "    print(\"Label prop...\")\n",
    "    #Label propogation method\n",
    "    #comm1.label_propagation_communities(g) #networkx implementation, doesn't seem to work\n",
    "    partition_label = g_ig.community_label_propagation()\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_label.membership)\n",
    "    partition_label_transpose = transposeDict(partition_memberships,items=True)\n",
    "    partition_label_transpose_relabel = {}\n",
    "    for thing in partition_label_transpose:\n",
    "        partition_label_transpose_relabel[thing] = set([g_ig_lookup_table_rev[x][0] for x in partition_label_transpose[thing]])\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_label_transpose_relabel,g_consensus_cluster)\n",
    "    adj_dict = incrementAdjacency(partition_label_transpose_relabel,adj_dict)\n",
    "    \n",
    "    print(\"Final...\")\n",
    "    #Final community assignment: igraph consensus cluster\n",
    "    partition_f = comm2.best_partition(g_consensus_cluster, weight='weight')\n",
    "    #Final community assignment: adj matrix clustering\n",
    "    g_num_nodes = nx.number_of_nodes(g)\n",
    "    adj_matrix = np.zeros((g_num_nodes,g_num_nodes))\n",
    "    for k,v in adj_dict.items():\n",
    "        adj_matrix[k[0],k[1]] += v\n",
    "    partition_f_adj = comm2.best_partition(nx.from_numpy_matrix(adj_matrix))\n",
    "    \n",
    "    df = pd.DataFrame([k_core,partition_f]).T.rename(index=str,columns={0:\"k_value\",1:\"Community_graph\",2:\"Community_adj\"})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-09-07_reg.pickle started...\n",
      "Calculating k-core\n",
      "Creating igraph\n",
      "Creating consensus cluster\n",
      "Louvain...\n",
      "Pushing\n",
      "Infomap...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'partition_info_transpose_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a3338da4e22c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworkCalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-78aec3d05fea>\u001b[0m in \u001b[0;36mnetworkCalc\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mpartition_info_transpose_relabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthing\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpartition_info_transpose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mpartition_info_transpose_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_ig_lookup_table_rev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpartition_info_transpose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;31m#Push to original graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mg_consensus_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincrementWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition_info_transpose_relabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_consensus_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partition_info_transpose_label' is not defined"
     ]
    }
   ],
   "source": [
    "df = networkCalc(os.listdir(networks_folder)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Processing (heh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(processes = 4)\n",
    "    \n",
    "    multiple_results = [pool.apply_async(networkCalc,(filename,)) for filename in os.listdir(networks_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiple_results[0].get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING AREA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
