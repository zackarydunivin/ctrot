{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel implementation of \"Analyzing networks\" notebook\n",
    "\n",
    "Like my other notebooks, this is a testing and staging notebook for a future python script. \n",
    "\n",
    "This script  will run all of the community detection methods on the networks in parallel and output the list of partitions into a pickled file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community as comm1\n",
    "import community as comm2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from collections import defaultdict #Used to transpose dictionary\n",
    "from itertools import combinations\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networks_folder = \"networks_folder/\"\n",
    "nodestats_folder = \"nodestats_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_nodes = [27522964, 42786325, 52352820, 72931184, 75736238, 87229781, 90657826, 114374226, 152852932, 154891961, 209693451, 271397818, 322027737, 402181258, 433462889, 1457805708, 2167525794, 2231109295, 2349347329, 2442888666, 2490088512, 2888660047, 2915187060, 2995401932, 3012158891, 3234613430, 3999537573, 813914393788481540, 817163123182465024, 832319306541178881, 850408392925499392, 857482409012547584, 894682675893735426, 903046544919732224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics of interest\n",
    "* Shortest path to seeds\n",
    "* Distribution of people in k-shells over time\n",
    "* Communities and their membership over time\n",
    "* Figure out centrality distribution for evenness. Are bots really high?\n",
    "\n",
    "Use LaNet-Vi to visualize k-core\n",
    "How do check for number of overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortestPath2Seeds(source_seed,seed_nodes,g):\n",
    "    test_minimum_path = []\n",
    "    #Remove edges from seed nodes\n",
    "    seed_nodes_in_graph = [x for x in seed_nodes if x in g]\n",
    "    if len(seed_nodes_in_graph)==0:\n",
    "        return -2\n",
    "    for remaining_seed in seed_nodes_in_graph:\n",
    "        removed_seed_edges = g.edges([x for x in seed_nodes if x!= remaining_seed])\n",
    "        h = nx.DiGraph(g)\n",
    "        h.remove_edges_from(removed_seed_edges)\n",
    "        if remaining_seed in h and nx.has_path(h,source_seed,remaining_seed):\n",
    "            test_minimum_path.append( len(nx.shortest_path(h,source_seed,remaining_seed)) )\n",
    "        #g.add_edges_from(removed_seed_edges)\n",
    "    if test_minimum_path==[]:\n",
    "        return -1\n",
    "    else: \n",
    "        return min(test_minimum_path)\n",
    "    \n",
    "def transposeDict(original_dict,items=False):\n",
    "    result = defaultdict(list)\n",
    "    items_l = original_dict.items() if not items else original_dict\n",
    "    for k,v in items_l:\n",
    "        result[v].append(k)\n",
    "    result = dict(result)\n",
    "    return result\n",
    "\n",
    "def incrementWeights(partition_transpose,g_temp,g_ig_lookup_table,is_ig=False): #CHANGE THIS TO ACTUALLY BE RIGHT\n",
    "    if is_ig:\n",
    "        g_ig_lookup_table_rev = transposeDict(g_ig_lookup_table)\n",
    "        for thing in partition_transpose:\n",
    "            partition_transpose[thing] = set([g_ig_lookup_table_rev[x][0] for x in partition_transpose[thing]])\n",
    "    for comm in partition_transpose:\n",
    "        for e1,e2 in combinations(partition_transpose[comm],2):\n",
    "            if g_temp.has_edge(e1,e2):\n",
    "                g_temp[e1][e2]['weight'] += 1\n",
    "#             else:\n",
    "#                 g.add_edge(e1,e2,attr_dict={'weight':1})\n",
    "    return g_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def networkCalc(filename):\n",
    "    print(\"%s started...\"%filename)\n",
    "    with open(networks_folder+filename,'rb') as f:\n",
    "        g = pickle.load(f)\n",
    "    k_core = nx.core_number(g)\n",
    "    shortest_paths_2_seeds = {}\n",
    "    for node in tqdm(g):\n",
    "        shortest_paths_2_seeds[node] = shortestPath2Seeds(node,seed_nodes,g)\n",
    "    \n",
    "    #Creating igraph\n",
    "    g_ig_lookup_table = {}\n",
    "    counter = 0\n",
    "    for node in g:\n",
    "        g_ig_lookup_table[node] = counter\n",
    "        counter += 1\n",
    "    g_ig = ig.Graph(len(g), [(g_ig_lookup_table[x],g_ig_lookup_table[y]) for x,y in list(g.edges()) if y!='None'])\n",
    "    #Creating consensus cluster\n",
    "    g_consensus_cluster = nx.Graph(g)\n",
    "    nx.set_edge_attributes(g_consensus_cluster,name='weight',values=0)\n",
    "    \n",
    "    #Communities over time - Using consensus clustering\n",
    "    #Louvain community\n",
    "    partition_lou = comm2.best_partition(nx.Graph(g))\n",
    "    partition_lou_transpose = transposeDict(partition_lou)\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_lou_transpose,g_consensus_cluster,g_ig_lookup_table)\n",
    "\n",
    "    #Infomap\n",
    "    partition_info = g_ig.community_infomap(trials=20)\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_info.membership)\n",
    "    partition_info_transpose = transposeDict(partition_memberships,items=True)\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_info_transpose,g_consensus_cluster,g_ig_lookup_table,is_ig=True)\n",
    "\n",
    "    #Label propogation method\n",
    "    #comm1.label_propagation_communities(g) #networkx implementation, doesn't seem to work\n",
    "    partition_label = g_ig.community_label_propagation()\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_label.membership)\n",
    "    partition_label_transpose = transposeDict(partition_memberships,items=True)\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_label_transpose,g_consensus_cluster,g_ig_lookup_table,is_ig=True)\n",
    "    \n",
    "    #Final community assignment\n",
    "    partition_f = comm2.best_partition(g_consensus_cluster, weight='weight')\n",
    "    \n",
    "    df = pd.DataFrame([k_core,shortest_paths_2_seeds,partition_f]).T.rename(index=str,columns={0:\"k_value\",1:\"SP2S\",2:\"Community\"})\n",
    "    with open(nodestats_folder+filename,'w') as f:\n",
    "        df.to_csv()\n",
    "    print(\"%s finished!\"%filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Processing (heh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-09-07_reg.pickle started...\n",
      "2013-09-07_reg.pickle finished!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(processes = 4)\n",
    "    \n",
    "    multiple_results = [pool.apply_async(networkCalc,(filename,)) for filename in os.listdir(networks_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_results[0].get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING AREA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
