{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel implementation of \"Analyzing networks\" notebook\n",
    "\n",
    "Like my other notebooks, this is a testing and staging notebook for a future python script. \n",
    "\n",
    "This script  will run all of the community detection methods on the networks in parallel and output the list of partitions into a pickled file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community as comm1\n",
    "import community as comm2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from collections import defaultdict #Used to transpose dictionary\n",
    "from itertools import combinations\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networks_folder = \"networks_folder/\"\n",
    "nodestats_folder = \"nodestats_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_nodes = [27522964, 42786325, 52352820, 72931184, 75736238, 87229781, 90657826, 114374226, 152852932, 154891961, 209693451, 271397818, 322027737, 402181258, 433462889, 1457805708, 2167525794, 2231109295, 2349347329, 2442888666, 2490088512, 2888660047, 2915187060, 2995401932, 3012158891, 3234613430, 3999537573, 813914393788481540, 817163123182465024, 832319306541178881, 850408392925499392, 857482409012547584, 894682675893735426, 903046544919732224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics of interest\n",
    "* Shortest path to seeds\n",
    "* Distribution of people in k-shells over time\n",
    "* Communities and their membership over time\n",
    "* Figure out centrality distribution for evenness. Are bots really high?\n",
    "\n",
    "Use LaNet-Vi to visualize k-core\n",
    "How do check for number of overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortestPath2Seeds(source_seed,seed_nodes,g):\n",
    "    test_minimum_path = []\n",
    "    #Remove edges from seed nodes\n",
    "    seed_nodes_in_graph = [x for x in seed_nodes if x in g]\n",
    "    if len(seed_nodes_in_graph)==0:\n",
    "        return -2\n",
    "    for remaining_seed in seed_nodes_in_graph:\n",
    "        removed_seed_edges = g.edges([x for x in seed_nodes if x!= remaining_seed])\n",
    "        h = nx.DiGraph(g)\n",
    "        h.remove_edges_from(removed_seed_edges)\n",
    "        if remaining_seed in h and nx.has_path(h,source_seed,remaining_seed):\n",
    "            test_minimum_path.append( len(nx.shortest_path(h,source_seed,remaining_seed)) )\n",
    "        #g.add_edges_from(removed_seed_edges)\n",
    "    if test_minimum_path==[]:\n",
    "        return -1\n",
    "    else: \n",
    "        return min(test_minimum_path)\n",
    "    \n",
    "def transposeDict(original_dict,items=False):\n",
    "    result = defaultdict(list)\n",
    "    items_l = original_dict.items() if not items else original_dict\n",
    "    for k,v in items_l:\n",
    "        result[v].append(k)\n",
    "    result = dict(result)\n",
    "    return result\n",
    "\n",
    "def incrementWeights(partition_transpose,g_temp):\n",
    "    for comm in partition_transpose:\n",
    "        for e1,e2 in combinations(partition_transpose[comm],2):\n",
    "            if g_temp.has_edge(e1,e2):\n",
    "                g_temp[e1][e2]['weight'] += 1\n",
    "    return g_temp\n",
    "\n",
    "def incrementAdjacency(partition_transpose, adj_dict):\n",
    "    for comm in partition_transpose:\n",
    "        for e1,e2 in combinations(partition_transpose[comm],2):\n",
    "            if (e1,e2) not in adj_dict:\n",
    "                adj_dict[(e1,e2)] = 0\n",
    "            adj_dict[(e1,e2)] += 1\n",
    "    return adj_dict\n",
    "\n",
    "def savedf(df):\n",
    "    with open(nodestats_folder+filename,'w') as f:\n",
    "        df.to_csv(f)\n",
    "    print(\"%s finished!\"%filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def networkCalc(filename):\n",
    "    with open(networks_folder+filename,'rb') as f:\n",
    "        g = pickle.load(f)\n",
    "    k_core = nx.core_number(g)\n",
    "#     shortest_paths_2_seeds = {}\n",
    "#     for node in tqdm(g):\n",
    "#         shortest_paths_2_seeds[node] = shortestPath2Seeds(node,seed_nodes,g)\n",
    "    \n",
    "    #Creating igraph\n",
    "    g_ig_lookup_table = {}\n",
    "    counter = 0\n",
    "    for node in g:\n",
    "        g_ig_lookup_table[node] = counter\n",
    "        counter += 1\n",
    "    g_ig = ig.Graph(len(g), [(g_ig_lookup_table[x],g_ig_lookup_table[y]) for x,y in list(g.edges()) if y!='None'])\n",
    "    g_ig_lookup_table_rev = transposeDict(g_ig_lookup_table)\n",
    "    \n",
    "    #Creating consensus cluster\n",
    "    g_consensus_cluster = nx.Graph(g)\n",
    "    nx.set_edge_attributes(g_consensus_cluster,name='weight',values=0)\n",
    "    #Creating consensus matrix\n",
    "    adj_dict = {}\n",
    "    \n",
    "    #Communities over time - Using consensus clustering\n",
    "    #Louvain community\n",
    "    partition_lou = comm2.best_partition(nx.Graph(g))\n",
    "    partition_lou_transpose = transposeDict(partition_lou)\n",
    "    \n",
    "    #Infomap\n",
    "    partition_info = g_ig.community_infomap(trials=20)\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_info.membership)\n",
    "    partition_info_transpose = transposeDict(partition_memberships,items=True)\n",
    "    partition_info_transpose_relabel = {}\n",
    "    for thing in partition_info_transpose:\n",
    "        partition_info_transpose_relabel[thing] = set([g_ig_lookup_table_rev[x][0] for x in partition_info_transpose[thing]])\n",
    "    \n",
    "    #Label propogation method\n",
    "    #comm1.label_propagation_communities(g) #networkx implementation, doesn't seem to work\n",
    "    partition_label = g_ig.community_label_propagation()\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_label.membership)\n",
    "    partition_label_transpose = transposeDict(partition_memberships,items=True)\n",
    "    partition_label_transpose_relabel = {}\n",
    "    for thing in partition_label_transpose:\n",
    "        partition_label_transpose_relabel[thing] = set([g_ig_lookup_table_rev[x][0] for x in partition_label_transpose[thing]])\n",
    "    \n",
    "    if True:\n",
    "        g_consensus_cluster = incrementWeights(partition_lou_transpose,g_consensus_cluster)\n",
    "        g_consensus_cluster = incrementWeights(partition_info_transpose_relabel,g_consensus_cluster)\n",
    "        g_consensus_cluster = incrementWeights(partition_label_transpose_relabel,g_consensus_cluster)\n",
    "        partition_f = comm2.best_partition(g_consensus_cluster, weight='weight')\n",
    "\n",
    "    if False:\n",
    "        adj_dict = incrementAdjacency(partition_lou_transpose,adj_dict)\n",
    "        adj_dict = incrementAdjacency(partition_info_transpose_relabel,adj_dict)\n",
    "        adj_dict = incrementAdjacency(partition_label_transpose_relabel,adj_dict)\n",
    "        g_num_nodes = nx.number_of_nodes(g)\n",
    "        adj_matrix = np.zeros((g_num_nodes,g_num_nodes))\n",
    "        for k,v in adj_dict.items():\n",
    "            adj_matrix[k[0],k[1]] += v\n",
    "        partition_f_adj = comm2.best_partition(nx.from_numpy_matrix(adj_matrix))\n",
    "           \n",
    "    df = pd.DataFrame([k_core,partition_f]).T.rename(index=str,columns={0:\"k_value\",1:\"Community_graph\"}) #,2:\"Community_adj\"})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Processing (heh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(processes = 4)\n",
    "    \n",
    "    multiple_results = [pool.apply_async(networkCalc,(filename,)) for filename in os.listdir(networks_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiple_results[0].get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING AREA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
