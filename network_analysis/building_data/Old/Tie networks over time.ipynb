{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx\n",
    "import community\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import sys\n",
    "import operator\n",
    "sys.path.insert(0, '/home/vincent/Documents/School/Research/EoBoR/')\n",
    "from hungarian import Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodestats_folder = \"nodestats_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transposeDict(original_dict,items=False):\n",
    "    from collections import defaultdict\n",
    "    result = defaultdict(list)\n",
    "    items_l = original_dict.items() if not items else original_dict\n",
    "    for k,v in items_l:\n",
    "        result[v].append(k)\n",
    "    result = dict(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling dynamic communities\n",
    "\n",
    "Two methods:\n",
    "* Hungarian method with cutoff\n",
    "* Santo's \"best match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pulling networks from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partitions_over_time = {}\n",
    "\n",
    "for filename in sorted(os.listdir(nodestats_folder)):\n",
    "    with open(nodestats_folder+filename,'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        for index,row in df.iterrows():\n",
    "            partitions_over_time[row['username']] = row['Community']\n",
    "\n",
    "partitions_over_time = transposeDict(partitions_over_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating test networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 25.56it/s]\n"
     ]
    }
   ],
   "source": [
    "networks_over_time = []\n",
    "partitions_over_time = []\n",
    "\n",
    "networks_over_time.append(nx.random_geometric_graph(500,0.125))\n",
    "partitions_over_time.append(transposeDict(dict(community.best_partition(networks_over_time[0]))))\n",
    "\n",
    "for x in tqdm(range(100)):\n",
    "    g = nx.Graph(networks_over_time[x])\n",
    "    #randomly delete a hundred nodes\n",
    "    removed_nodes = []\n",
    "    for i in range(100):\n",
    "        removed_node = np.random.choice(list(g.nodes()))\n",
    "        removed_nodes.append(removed_node)\n",
    "        g.remove_node(removed_node)\n",
    "    for i in list(nx.isolates(g)):\n",
    "        g.remove_node(i)\n",
    "        removed_nodes.append(i)\n",
    "    #randomly add nodes by neighbors\n",
    "    for node in removed_nodes:\n",
    "        if nx.number_of_nodes(g)==0:\n",
    "            g.add_node(node)\n",
    "        elif nx.number_of_nodes(g)==1:\n",
    "            g.add_edge(list(g.nodes())[0],node)\n",
    "        else:\n",
    "            neighbors = []\n",
    "            while neighbors==[]:\n",
    "                select_node = np.random.choice(list(g.nodes()))\n",
    "                neighbors = list(g.neighbors(select_node))\n",
    "            neighbors_deg = [j for q,j in list(g.degree(neighbors))]\n",
    "            neighbors_deg = [j/sum(neighbors_deg) for j in neighbors_deg]\n",
    "            select_neighbor = np.random.choice(neighbors,p=neighbors_deg)\n",
    "            g.add_edge(select_neighbor,node)\n",
    "    networks_over_time.append(g)\n",
    "    partitions_over_time.append(transposeDict(dict(community.best_partition(g))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hungarian method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating reassignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If there is a forward map and it matches the backward map, then it's good. \n",
    "* If there is a forward map but a different backward map, it means a forward handoff (comm1 becomes comm2)\n",
    "* If there is a backward map but a different forward map, same kind of handoff but different specific handoff. \n",
    "* If there is no backward map, the community dies. \n",
    "* If there is no forward map, the community is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateReassignments(partitions_over_time):\n",
    "    reassignment_partitions = []\n",
    "\n",
    "    prev_part = partitions_over_time[0]#Start with the first one in the time series\n",
    "    reassignment_partitions.append({x:x for x in prev_part.keys()}) #Initialize a 1-1 mapping for first part\n",
    "    for next_part in tqdm(partitions_over_time[1:]):\n",
    "        #Computer matrix of Jaccard distances between communities\n",
    "        jacmatrix = np.zeros((len(prev_part),len(next_part)))\n",
    "        for x in prev_part.keys():\n",
    "            for y in next_part.keys():\n",
    "                one = set(prev_part[x])\n",
    "                two = set(next_part[y])\n",
    "                jacmatrix[int(x)][int(y)] = 1 - len(one&two)/len(one|two)  ### DOES THIS NEED A THRESHOLD???\n",
    "        #Hungarian from prev to next (forward)\n",
    "        hungarian = Hungarian(jacmatrix)\n",
    "        hungarian.calculate()\n",
    "        forward_map = hungarian.get_results()\n",
    "        \n",
    "        #TEST SCENARIO\n",
    "        valid_partitions = forward_map\n",
    "        #Create a reassignment dictionary for next_part\n",
    "        this_assignment_dict = {y:x for x,y in valid_partitions} #Formatted as \"this_key:will_become_this_val\"\n",
    "\n",
    "        reassignment_partitions.append(this_assignment_dict)\n",
    "        prev_part = next_part\n",
    "    return reassignment_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirming reassignments\n",
    "\n",
    "At this point, `reassignment_partitions` is a list of dictionaries that tell you how to relabel communities to the corresponding label of the previous time step. \n",
    "\n",
    "The following generates `final_partitions`, a list of dictionaries that tell you how to relabel communities to an absolute label over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finalizingPartitions(reassignment_partitions):\n",
    "    final_partitions = []\n",
    "    final_partitions.append(reassignment_partitions[0])\n",
    "    prev_dict = reassignment_partitions[0]\n",
    "    new_comm_label = max([int(x) for x in prev_dict.keys()]) + 1\n",
    "\n",
    "    #Go through the reassignments\n",
    "    for x in range(len(reassignment_partitions[1:])):\n",
    "        current_dict = copy.deepcopy(reassignment_partitions[x])\n",
    "        for k,v in current_dict.items():\n",
    "            if v in prev_dict.keys():\n",
    "                current_dict[k] = prev_dict[v]\n",
    "            elif v not in prev_dict.keys():\n",
    "                current_dict[k] = new_comm_label\n",
    "                new_comm_label+=1\n",
    "        final_partitions.append(current_dict)\n",
    "        prev_dict = current_dict\n",
    "    return final_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing example networks with Hungarian\n",
    "\n",
    "8/6/18 -- There are issues where Hungarian can't do a forward and backward map so it can't sense when new communities are created. Also, because the mapping forces a 1-to-1 relationship, there's an issue with overzealous fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reassignment_partitions = generateReassignments(partitions_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_partitions = finalizingPartitions(reassignment_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "converted_partitions_over_time = []\n",
    "\n",
    "for x,part in enumerate(partitions_over_time):\n",
    "    print(x)\n",
    "    result = {final_partitions[x][k]:part[k] for k in part}\n",
    "    converted_partitions_over_time.append( result )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santo reassignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design conceits\n",
    "\n",
    "By keeping track of forward and backward maximum matches by Jaccard distance, this opens the possibility for a lot of different ways for communities to merge in and one of each other. \n",
    "\n",
    "It's relatively clear that if two communities has a best forward match with the same subsequent community, a merge has occurred. It is also relatively clear that if two communities draw from the same previous community, a split has occurred. \n",
    "\n",
    "It's not clear how to label communities that exchange members. So for the sake of this work, I'm just going to say that we're keeping track of splits but not merges. However, this opens up the possibility for a ship of theseus problem with a community that routinely exchanges members. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def santoReassignments(partitions_over_time, tau = 0.05):\n",
    "    reassignment_partitions = []\n",
    "    \n",
    "    prev_part = partitions_over_time[0] #Start with the first one in the time series\n",
    "    reassignment_partitions.append({x:x for x in prev_part.keys()}) #Initialize a 1-1 mapping for first part\n",
    "    max_k = max(list(prev_part.keys()))\n",
    "\n",
    "    for i in tqdm(range(1,len(partitions_over_time))):\n",
    "        next_part = partitions_over_time[i]\n",
    "        jacmatrix = {}\n",
    "        for x in prev_part.keys():\n",
    "            if x not in jacmatrix:\n",
    "                jacmatrix[x] = {}\n",
    "            for y in next_part.keys():\n",
    "                one = set(prev_part[x])\n",
    "                two = set(next_part[y])\n",
    "                temp = len(one&two)/len(one|two)\n",
    "                jacmatrix[int(x)][int(y)] = temp if temp>tau else 0\n",
    "        jacmatrix_t = {}\n",
    "        for bigkey in jacmatrix:\n",
    "            for smallkey in jacmatrix[bigkey]:\n",
    "                if smallkey not in jacmatrix_t:\n",
    "                    jacmatrix_t[smallkey] = {}\n",
    "                if bigkey not in jacmatrix_t[smallkey]:\n",
    "                    jacmatrix_t[smallkey][bigkey] = jacmatrix[bigkey][smallkey]\n",
    "        \n",
    "        forward_mapping = {}\n",
    "        backward_mapping = {}\n",
    "        for bigkey in jacmatrix:\n",
    "            forward_mapping[bigkey] = max(jacmatrix[bigkey].items(), key=operator.itemgetter(1))[0]\n",
    "        for bigkey in jacmatrix_t:\n",
    "            backward_mapping[bigkey] = max(jacmatrix_t[bigkey].items(), key=operator.itemgetter(1))[0]\n",
    "                \n",
    "        old_map = reassignment_partitions[-1]\n",
    "        new_map = {}\n",
    "        #new_relabels = {}\n",
    "        #If something says it tracks forward, then track it\n",
    "        forward_mapping_t = transposeDict(forward_mapping)\n",
    "        for k_1,v_0 in forward_mapping_t.items():\n",
    "            if len(v_0)==1: #One-to-one forward relationship\n",
    "                new_map[v_0[0]] = k_1\n",
    "            elif len(v_0)>1: #One-to-many forward relationship\n",
    "                max_v = -1\n",
    "                max_v_index = -1\n",
    "                for thing in v_0: #Get the largest similarity score\n",
    "                    if jacmatrix[thing][k_1]>max_v:\n",
    "                        max_v = jacmatrix[thing][k_1]\n",
    "                        max_v_index = thing\n",
    "                new_map[max_v_index] = k_1\n",
    "                #Record the rest as being possible MERGES\n",
    "#                 for thing in [jk for jk in v_0 if jk!=max_v_index]:\n",
    "#                     problem_mappings[thing] = k_1\n",
    "        backward_mapping_t = transposeDict(backward_mapping)\n",
    "        for k_0,v_1 in backward_mapping_t.items():\n",
    "            if len(v_1)==1 and k_0 in new_map and new_map[k_0]==v_1[0]:\n",
    "                pass #Confirm sustain\n",
    "            elif len(v_1)>1:\n",
    "                for thing in v_1:\n",
    "                    if k_0 in new_map and new_map[k_0]==thing:\n",
    "                        pass #Confirm it's already being written in, so a sustain\n",
    "                    elif k_0 in new_map and new_map[k_0]!=thing:\n",
    "                        #Confirm a split\n",
    "                        new_map[max_k] = thing\n",
    "                        max_k += 1\n",
    "                        #Don't actually have to keep track of mappings to newly relabeled communities\n",
    "                    elif k_0 not in new_map:\n",
    "                        new_map[k_0] = thing #Only a backward relationship\n",
    "        #Reverse new_map so that it becomes a dictionary of relabels\n",
    "        #Filter new_map through old_map\n",
    "        new_names = {v:k if k not in old_map else old_map[k] for k,v in new_map.items()}\n",
    "        \n",
    "        reassignment_partitions.append(new_names)\n",
    "        prev_part = next_part\n",
    "    \n",
    "    return reassignment_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing example networks with Santo\n",
    "\n",
    "8/6/18 -- Need to add in the ability to do both forward and backward mapping. Draft of this has been started above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1508.52it/s]\n"
     ]
    }
   ],
   "source": [
    "santo_reassignment_partitions = santoReassignments(partitions_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7},\n",
       " {0: 0, 1: 1, 2: 2, 3: 6, 4: 7, 5: 4, 6: 3, 7: 5},\n",
       " {0: 0, 1: 1, 2: 2, 3: 6, 4: 7, 5: 4, 6: 3, 7: 5, 8: 8},\n",
       " {0: 0, 1: 2, 2: 6, 3: 4, 4: 3, 5: 1, 6: 8, 7: 7},\n",
       " {0: 0, 1: 2, 2: 8, 3: 4, 4: 3, 5: 1, 6: 6, 7: 8, 8: 7},\n",
       " {0: 0, 1: 2, 2: 3, 3: 8, 4: 4, 5: 1, 6: 6, 7: 9, 8: 8, 9: 10, 10: 7},\n",
       " {0: 8,\n",
       "  1: 2,\n",
       "  2: 14,\n",
       "  3: 8,\n",
       "  4: 9,\n",
       "  5: 4,\n",
       "  6: 3,\n",
       "  7: 1,\n",
       "  8: 6,\n",
       "  9: 0,\n",
       "  10: 10,\n",
       "  11: 16,\n",
       "  12: 11,\n",
       "  13: 17,\n",
       "  14: 15,\n",
       "  15: 12,\n",
       "  16: 13},\n",
       " {0: 8,\n",
       "  1: 0,\n",
       "  2: 9,\n",
       "  3: 4,\n",
       "  4: 14,\n",
       "  5: 3,\n",
       "  6: 1,\n",
       "  7: 6,\n",
       "  8: 10,\n",
       "  9: 16,\n",
       "  10: 20,\n",
       "  11: 18,\n",
       "  12: 19,\n",
       "  13: 15,\n",
       "  14: 17,\n",
       "  15: 8,\n",
       "  16: 12,\n",
       "  17: 13},\n",
       " {0: 8,\n",
       "  1: 0,\n",
       "  2: 9,\n",
       "  3: 21,\n",
       "  4: 22,\n",
       "  5: 14,\n",
       "  6: 3,\n",
       "  7: 16,\n",
       "  8: 1,\n",
       "  9: 23,\n",
       "  10: 18,\n",
       "  11: 6,\n",
       "  12: 13,\n",
       "  13: 19,\n",
       "  15: 20,\n",
       "  16: 17,\n",
       "  17: 8,\n",
       "  18: 12},\n",
       " {0: 8,\n",
       "  1: 22,\n",
       "  2: 21,\n",
       "  3: 9,\n",
       "  4: 26,\n",
       "  5: 24,\n",
       "  6: 3,\n",
       "  7: 16,\n",
       "  8: 1,\n",
       "  9: 23,\n",
       "  10: 14,\n",
       "  11: 20,\n",
       "  12: 27,\n",
       "  13: 6,\n",
       "  14: 14,\n",
       "  15: 0,\n",
       "  16: 28,\n",
       "  17: 19,\n",
       "  18: 8,\n",
       "  19: 17,\n",
       "  20: 12,\n",
       "  21: 25},\n",
       " {0: 24,\n",
       "  1: 3,\n",
       "  2: 8,\n",
       "  3: 9,\n",
       "  4: 21,\n",
       "  5: 14,\n",
       "  6: 26,\n",
       "  7: 16,\n",
       "  8: 8,\n",
       "  9: 1,\n",
       "  10: 19,\n",
       "  11: 20,\n",
       "  12: 22,\n",
       "  13: 30,\n",
       "  14: 6,\n",
       "  15: 0,\n",
       "  16: 23,\n",
       "  17: 28,\n",
       "  18: 25,\n",
       "  19: 17,\n",
       "  20: 14,\n",
       "  21: 12,\n",
       "  22: 29},\n",
       " {0: 24,\n",
       "  1: 20,\n",
       "  2: 3,\n",
       "  3: 8,\n",
       "  4: 9,\n",
       "  5: 25,\n",
       "  6: 14,\n",
       "  7: 23,\n",
       "  8: 31,\n",
       "  9: 8,\n",
       "  10: 1,\n",
       "  11: 19,\n",
       "  12: 16,\n",
       "  13: 0,\n",
       "  14: 22,\n",
       "  15: 30,\n",
       "  16: 6,\n",
       "  17: 21,\n",
       "  18: 32,\n",
       "  19: 28,\n",
       "  20: 17,\n",
       "  21: 14,\n",
       "  22: 12,\n",
       "  23: 29},\n",
       " {0: 24,\n",
       "  1: 20,\n",
       "  2: 3,\n",
       "  3: 8,\n",
       "  4: 30,\n",
       "  5: 23,\n",
       "  6: 14,\n",
       "  7: 31,\n",
       "  8: 21,\n",
       "  9: 8,\n",
       "  10: 1,\n",
       "  11: 19,\n",
       "  12: 0,\n",
       "  13: 17,\n",
       "  14: 14,\n",
       "  15: 12,\n",
       "  16: 32,\n",
       "  17: 28,\n",
       "  18: 29,\n",
       "  19: 6},\n",
       " {0: 31,\n",
       "  1: 17,\n",
       "  2: 0,\n",
       "  3: 14,\n",
       "  4: 24,\n",
       "  5: 8,\n",
       "  6: 14,\n",
       "  7: 23,\n",
       "  8: 3,\n",
       "  9: 21,\n",
       "  10: 1,\n",
       "  11: 30,\n",
       "  12: 8,\n",
       "  13: 20,\n",
       "  14: 33,\n",
       "  15: 19,\n",
       "  16: 34,\n",
       "  17: 12,\n",
       "  18: 32,\n",
       "  19: 35,\n",
       "  20: 28,\n",
       "  21: 29,\n",
       "  22: 6},\n",
       " {0: 12,\n",
       "  1: 17,\n",
       "  2: 8,\n",
       "  3: 23,\n",
       "  4: 8,\n",
       "  5: 14,\n",
       "  6: 36,\n",
       "  7: 21,\n",
       "  8: 31,\n",
       "  9: 0,\n",
       "  10: 35,\n",
       "  11: 30,\n",
       "  12: 20,\n",
       "  13: 3,\n",
       "  14: 33,\n",
       "  15: 19,\n",
       "  16: 34,\n",
       "  17: 14,\n",
       "  18: 32,\n",
       "  19: 28,\n",
       "  20: 6},\n",
       " {0: 17,\n",
       "  1: 8,\n",
       "  2: 8,\n",
       "  3: 23,\n",
       "  4: 3,\n",
       "  5: 36,\n",
       "  6: 21,\n",
       "  7: 31,\n",
       "  8: 30,\n",
       "  9: 14,\n",
       "  10: 20,\n",
       "  11: 33,\n",
       "  12: 12,\n",
       "  13: 37,\n",
       "  14: 19,\n",
       "  15: 34,\n",
       "  16: 28,\n",
       "  17: 6,\n",
       "  18: 35},\n",
       " {0: 23,\n",
       "  1: 8,\n",
       "  2: 30,\n",
       "  3: 8,\n",
       "  4: 3,\n",
       "  5: 33,\n",
       "  6: 36,\n",
       "  7: 21,\n",
       "  8: 17,\n",
       "  9: 14,\n",
       "  10: 12,\n",
       "  11: 19,\n",
       "  12: 34,\n",
       "  13: 35,\n",
       "  14: 28,\n",
       "  15: 6,\n",
       "  16: 38},\n",
       " {0: 23,\n",
       "  1: 8,\n",
       "  2: 30,\n",
       "  3: 36,\n",
       "  4: 8,\n",
       "  5: 3,\n",
       "  6: 21,\n",
       "  7: 14,\n",
       "  8: 38,\n",
       "  9: 33,\n",
       "  10: 19,\n",
       "  11: 35,\n",
       "  12: 34,\n",
       "  13: 28,\n",
       "  14: 6,\n",
       "  15: 12,\n",
       "  16: 39,\n",
       "  17: 40},\n",
       " {0: 23,\n",
       "  1: 8,\n",
       "  2: 30,\n",
       "  3: 36,\n",
       "  4: 8,\n",
       "  5: 21,\n",
       "  6: 14,\n",
       "  7: 35,\n",
       "  8: 3,\n",
       "  9: 6,\n",
       "  10: 34,\n",
       "  11: 28,\n",
       "  12: 40,\n",
       "  13: 12,\n",
       "  14: 39},\n",
       " {0: 23,\n",
       "  1: 30,\n",
       "  2: 3,\n",
       "  3: 36,\n",
       "  4: 8,\n",
       "  5: 21,\n",
       "  6: 35,\n",
       "  7: 8,\n",
       "  8: 14,\n",
       "  9: 34,\n",
       "  10: 28,\n",
       "  11: 40,\n",
       "  12: 12,\n",
       "  13: 39},\n",
       " {0: 23,\n",
       "  1: 30,\n",
       "  2: 3,\n",
       "  3: 21,\n",
       "  5: 35,\n",
       "  6: 8,\n",
       "  7: 14,\n",
       "  9: 12,\n",
       "  10: 40,\n",
       "  11: 28,\n",
       "  12: 41,\n",
       "  13: 39},\n",
       " {0: 23,\n",
       "  1: 30,\n",
       "  2: 35,\n",
       "  3: 3,\n",
       "  4: 21,\n",
       "  5: 4,\n",
       "  6: 8,\n",
       "  7: 14,\n",
       "  8: 8,\n",
       "  9: 12,\n",
       "  10: 40,\n",
       "  11: 41,\n",
       "  12: 28},\n",
       " {0: 23, 1: 30, 2: 35, 3: 21, 4: 8, 5: 4, 6: 14, 7: 8, 8: 40, 9: 28},\n",
       " {0: 23, 1: 30, 2: 35, 3: 21, 4: 8, 5: 4, 6: 8, 7: 14, 8: 42, 9: 43, 10: 28},\n",
       " {0: 23, 1: 30, 2: 35, 3: 14, 4: 4, 5: 44, 6: 43, 7: 45, 8: 46},\n",
       " {0: 23, 1: 30, 2: 35, 3: 14, 4: 4, 5: 48, 6: 44, 7: 47},\n",
       " {0: 23, 1: 14, 2: 4, 3: 48, 4: 44, 5: 47, 6: 49},\n",
       " {0: 23, 1: 50, 2: 4, 3: 14, 4: 48, 5: 47, 6: 49},\n",
       " {0: 23, 1: 50, 2: 48, 3: 47, 4: 49},\n",
       " {0: 23, 1: 51, 2: 52, 3: 53, 4: 54, 5: 47, 6: 55, 7: 56},\n",
       " {0: 23,\n",
       "  1: 51,\n",
       "  2: 53,\n",
       "  3: 57,\n",
       "  4: 47,\n",
       "  5: 55,\n",
       "  6: 58,\n",
       "  7: 56,\n",
       "  8: 59,\n",
       "  10: 60,\n",
       "  11: 61},\n",
       " {0: 23, 1: 51, 2: 53, 3: 9, 4: 57, 5: 47, 6: 58, 7: 55, 8: 61, 9: 56, 10: 60},\n",
       " {0: 23, 1: 51, 2: 9, 3: 47, 4: 56, 5: 61, 6: 58, 7: 55, 8: 60},\n",
       " {0: 23, 1: 51, 2: 9, 3: 58, 4: 47, 5: 56, 6: 61, 7: 55},\n",
       " {0: 23, 1: 51, 2: 9, 3: 58, 4: 56, 5: 47, 6: 61, 7: 55},\n",
       " {0: 23, 1: 51, 2: 58, 3: 56, 4: 61, 5: 55},\n",
       " {0: 23, 1: 61, 2: 56, 3: 55},\n",
       " {0: 23, 1: 61, 2: 55, 3: 62},\n",
       " {0: 23, 1: 61, 2: 55, 3: 62},\n",
       " {0: 23, 1: 55, 2: 62},\n",
       " {0: 23, 1: 63, 2: 64, 3: 55, 4: 62, 5: 65, 6: 66, 7: 67},\n",
       " {0: 23, 1: 63, 2: 64, 3: 55, 4: 65, 5: 66, 6: 67, 7: 68},\n",
       " {0: 69, 1: 63, 2: 23, 3: 71, 4: 72, 5: 55, 6: 64, 7: 70, 8: 74, 9: 73},\n",
       " {0: 69,\n",
       "  1: 23,\n",
       "  2: 63,\n",
       "  3: 71,\n",
       "  4: 72,\n",
       "  5: 55,\n",
       "  6: 70,\n",
       "  7: 74,\n",
       "  8: 64,\n",
       "  9: 75,\n",
       "  10: 76,\n",
       "  11: 73},\n",
       " {0: 69,\n",
       "  1: 23,\n",
       "  2: 63,\n",
       "  3: 71,\n",
       "  4: 72,\n",
       "  5: 55,\n",
       "  6: 76,\n",
       "  7: 70,\n",
       "  8: 74,\n",
       "  9: 64,\n",
       "  10: 75,\n",
       "  11: 73},\n",
       " {0: 69, 1: 23, 2: 71, 3: 72, 4: 76, 5: 70, 6: 74, 7: 64, 8: 77},\n",
       " {0: 69,\n",
       "  1: 74,\n",
       "  2: 72,\n",
       "  3: 71,\n",
       "  4: 70,\n",
       "  5: 76,\n",
       "  6: 78,\n",
       "  7: 79,\n",
       "  8: 80,\n",
       "  9: 77,\n",
       "  10: 81},\n",
       " {0: 69, 1: 72, 2: 71, 3: 70, 4: 76, 5: 78, 6: 74, 7: 80, 8: 81},\n",
       " {0: 69, 1: 72, 2: 71, 3: 82, 4: 76, 5: 78, 6: 74, 7: 70, 8: 81},\n",
       " {0: 69, 1: 72, 2: 71, 3: 82, 4: 78, 5: 74, 6: 70, 7: 81},\n",
       " {0: 69, 1: 72, 2: 74, 3: 82, 4: 78, 5: 83, 6: 71, 7: 81},\n",
       " {0: 84, 1: 69, 2: 81, 3: 82, 4: 71, 5: 83, 6: 78, 7: 85},\n",
       " {0: 84, 1: 69, 2: 81, 3: 82, 4: 71, 5: 78, 6: 85},\n",
       " {0: 84, 1: 69, 2: 82, 3: 71, 4: 85},\n",
       " {0: 84, 1: 69, 2: 82, 3: 71, 4: 85},\n",
       " {0: 84, 1: 69, 2: 82, 3: 85, 4: 86, 5: 71},\n",
       " {0: 69, 1: 84, 2: 82, 3: 71, 4: 86},\n",
       " {0: 69, 1: 71, 2: 87},\n",
       " {0: 69, 1: 71},\n",
       " {0: 69, 1: 71},\n",
       " {0: 69, 1: 88, 2: 71},\n",
       " {0: 69, 1: 88, 2: 71},\n",
       " {0: 69},\n",
       " {0: 69},\n",
       " {0: 69},\n",
       " {0: 69},\n",
       " {0: 69},\n",
       " {0: 69},\n",
       " {0: 69, 1: 89},\n",
       " {0: 69},\n",
       " {0: 69},\n",
       " {0: 69, 1: 90},\n",
       " {0: 69, 1: 90},\n",
       " {0: 69, 1: 90},\n",
       " {0: 69, 1: 90},\n",
       " {0: 69, 1: 90},\n",
       " {0: 69, 1: 90},\n",
       " {0: 69, 1: 91, 2: 92, 3: 93, 4: 94},\n",
       " {0: 69, 1: 94, 2: 92, 3: 93},\n",
       " {0: 69, 1: 93, 2: 94},\n",
       " {0: 95, 1: 69, 2: 96, 3: 93, 4: 97, 5: 98, 6: 99},\n",
       " {0: 95, 1: 69, 2: 96, 3: 93, 4: 97, 5: 99},\n",
       " {0: 95, 1: 69, 2: 96, 3: 93, 4: 97},\n",
       " {0: 95, 1: 69, 2: 96, 3: 93, 4: 100},\n",
       " {0: 95, 1: 96, 2: 101},\n",
       " {0: 95, 1: 96, 2: 101, 3: 102},\n",
       " {0: 95, 1: 96},\n",
       " {0: 95, 1: 96},\n",
       " {0: 95, 1: 96},\n",
       " {0: 95, 1: 103, 2: 104},\n",
       " {0: 95, 1: 105, 2: 106},\n",
       " {0: 95, 1: 106},\n",
       " {0: 95, 1: 107, 2: 108, 3: 109, 4: 110, 5: 111, 6: 112},\n",
       " {0: 95, 1: 107, 2: 109, 3: 110, 4: 111, 6: 112},\n",
       " {0: 95, 1: 107, 2: 113, 3: 111, 4: 5, 5: 112},\n",
       " {0: 95, 1: 107, 2: 113, 3: 111, 4: 5, 5: 112},\n",
       " {0: 95, 1: 107, 2: 113, 3: 111, 4: 5, 5: 112},\n",
       " {0: 95, 1: 111, 2: 114, 3: 5},\n",
       " {0: 95, 1: 111, 2: 115, 3: 114, 4: 5},\n",
       " {0: 95, 1: 5, 2: 111, 3: 114},\n",
       " {0: 95, 1: 5, 2: 111, 3: 114}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "santo_reassignment_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRInalizingPartitions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-57248d147e20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msanto_final_partitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRInalizingPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanto_reassignment_partitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TRInalizingPartitions' is not defined"
     ]
    }
   ],
   "source": [
    "santo_final_partitions = TRInalizingPartitions(santo_reassignment_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting results to original dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NEED STUFF HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {x:np.random.randint(0,5) for x in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposeDict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        sustain = {}\n",
    "        forward_pass = {}\n",
    "        backward_pass = {}\n",
    "        for k_f,v_f in forward_mapping.items():\n",
    "            for k_b,v_b in backward_mapping.items():\n",
    "                if k_f==v_b and v_f==k_b:\n",
    "                    sustain[k_f] = v_f\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not sure if I'll still need this code\n",
    "\n",
    "def TRInalizingPartitions(reassignment_partitions):\n",
    "    final_partitions = []\n",
    "    final_partitions.append(reassignment_partitions[0])\n",
    "    prev_dict = reassignment_partitions[0]\n",
    "    new_comm_label = max([int(x) for x in prev_dict.keys()]) + 1\n",
    "\n",
    "    #Here, reassignment_partitions == (sustain, forward_pass, backward_pass)\n",
    "    for x in tqdm(range(1,len(reassignment_partitions[1:]))):\n",
    "        current_sustain = copy.deepcopy(reassignment_partitions[x][0])\n",
    "        current_forward = copy.deepcopy(reassignment_partitions[x][1])\n",
    "        current_backward = copy.deepcopy(reassignment_partitions[x][2])\n",
    "        current_dict = {}\n",
    "        accommodated_keys = set()\n",
    "        print(reassignment_partitions[x])\n",
    "        print(current_sustain)\n",
    "        for k,v in current_sustain.items():\n",
    "            if v in prev_dict.keys():\n",
    "                current_dict[k] = prev_dict[v]\n",
    "                accommodated_keys.add(k)\n",
    "            #else: actually this is okay because it means it exists in forward or backward passes\n",
    "                #raise ValueError(\"Something went wrong. A sustain was unable to locate its originating source.\")\n",
    "        for k,v in current_forward.items():\n",
    "            accommodated_keys.add(k)\n",
    "        for k,v in current_backward.items():\n",
    "            current_dict[k] = new_comm_label\n",
    "            new_comm_label += 1\n",
    "        if set(list(prev_dict.keys()))!=accommodated_keys:\n",
    "            print(list(prev_dict.keys()))\n",
    "            print(accommodated_keys)\n",
    "            raise ValueError(\"Missing something\")\n",
    "        final_partitions.append(current_dict)\n",
    "    return final_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        for k,v in backward_mapping.items():\n",
    "            if v in new_map and new_map[v]==k:\n",
    "                pass #CONFIRMED SUSTAINS\n",
    "            elif v in new_map and new_map[v]!=k:\n",
    "                #FORWARD PASS\n",
    "            else:\n",
    "                [DO SOMETHING ABOUT THE NEW COMMUNITIES]\n",
    "        #Keep track of renamings?\n",
    "        #Double entry book-keeping. \n",
    "            #Make sure that all your sustains, births, and deaths add up to the pre- and post-community counts\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def santoReassignments(partitions_over_time):\n",
    "    reassignment_partitions = []\n",
    "    \n",
    "    prev_part = partitions_over_time[0] #Start with the first one in the time series\n",
    "    reassignment_partitions.append({x:x for x in prev_part.keys()}) #Initialize a 1-1 mapping for first part\n",
    "    max_k = max(list(prev_part.keys()))\n",
    "    \n",
    "    for i in tqdm(range(1,len(partitions_over_time[1:]))):\n",
    "        next_part = partitions_over_time[i]\n",
    "        jacmatrix = np.zeros((len(prev_part),len(next_part)))\n",
    "        for x in prev_part.keys():\n",
    "            for y in next_part.keys():\n",
    "                one = set(prev_part[x])\n",
    "                two = set(next_part[y])\n",
    "                jacmatrix[int(x)][int(y)] = 1 - len(one&two)/len(one|two)\n",
    "        forward_mapping = {}\n",
    "        for x in range(len(jacmatrix)):\n",
    "            forward_mapping[x] = np.argmin(jacmatrix[x][:])\n",
    "        jacmatrix_t = np.transpose(jacmatrix)\n",
    "        backward_mapping = {}\n",
    "        for x in range(len(jacmatrix_t)):\n",
    "            backward_mapping[x] = np.argmin(jacmatrix_t[x][:])\n",
    "        \n",
    "        #Sustain: If forward mapping equals backward mapping\n",
    "        sustains = {x:forward_mapping[x] for x in forward_mapping if forward_mapping[x] in backward_mapping and backward_mapping[forward_mapping[x]]==x} \n",
    "        #Forward pass: Ends current community\n",
    "        forward_pass = {x:forward_mapping[x] for x in forward_mapping if forward_mapping[x] in backward_mapping and backward_mapping[forward_mapping[x]]!=x}\n",
    "        #Backward pass: Creates new community\n",
    "        backward_pass = {x:backward_mapping[x] for x in backward_mapping if backward_mapping[x] in forward_mapping and forward_mapping[backward_mapping[x]]!=x}\n",
    "        #SOMETHING FUNKY WITH BACKWARD PASSES\n",
    "        \n",
    "        old_map = reassignment_partitions[-1]\n",
    "        new_map = {}\n",
    "        print(\"Old map\", old_map)\n",
    "        print(\"Sustains\", sustains)\n",
    "        print(\"Forward passes\", forward_pass)\n",
    "        print(\"Backward passes\", backward_pass)\n",
    "        for k,v in sustains.items():\n",
    "            new_map[k] = old_map[v]\n",
    "        #Ignore forward passes\n",
    "        for k,v in backward_pass.items():\n",
    "            #new_k = max_k if k<=max_k else k #If the comm already existed in a previous step, make a new one\n",
    "            #max_k += 1\n",
    "            new_k = k\n",
    "            new_map[new_k] = old_map[v]\n",
    "        print(\"New map\", new_map)\n",
    "        reassignment_partitions.append(new_map)\n",
    "        \n",
    "        #Update the partition jaccard comparison thingy\n",
    "        prev_part = next_part\n",
    "        \n",
    "    return reassignment_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        for x in range(len(prev_part)): #REWRITE \n",
    "            if np.maximum(jacmatrix[x][:]) != 0:\n",
    "                forward_mapping[x] = np.argmax(jacmatrix[x][:])\n",
    "        jacmatrix_t = np.transpose(jacmatrix)\n",
    "        for x in range(len(next_part)):\n",
    "            if np.maximum(jacmatrix_t[x][:]) != 0:\n",
    "                backward_mapping[x] = np.argmax(jacmatrix_t[x][:])\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
