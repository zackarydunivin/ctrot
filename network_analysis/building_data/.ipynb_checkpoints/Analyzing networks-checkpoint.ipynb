{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import community as comm1\n",
    "import community as comm2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict #Used to transpose dictionary\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networks_folder = \"networks_folder/\"\n",
    "nodestats_folder = \"nodestats_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_nodes = [27522964, 42786325, 52352820, 72931184, 75736238, 87229781, 90657826, 114374226, 152852932, 154891961, 209693451, 271397818, 322027737, 402181258, 433462889, 1457805708, 2167525794, 2231109295, 2349347329, 2442888666, 2490088512, 2888660047, 2915187060, 2995401932, 3012158891, 3234613430, 3999537573, 813914393788481540, 817163123182465024, 832319306541178881, 850408392925499392, 857482409012547584, 894682675893735426, 903046544919732224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(networks_folder+'2013-09-07_reg.pickle','rb') as f:\n",
    "    g = pickle.load(f)\n",
    "#Making iGraph, because networkx doesn't have good native community detection\n",
    "#igraph graph can't store userid so using lookup table\n",
    "g_ig_lookup_table = {}\n",
    "counter = 0\n",
    "for node in g:\n",
    "    g_ig_lookup_table[node] = counter\n",
    "    counter += 1\n",
    "g_ig = ig.Graph(len(g), [(g_ig_lookup_table[x],g_ig_lookup_table[y]) for x,y in list(g.edges()) if y!='None'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortestPath2Seeds(source_seed,seed_nodes,g):\n",
    "    test_minimum_path = []\n",
    "    #Remove edges from seed nodes\n",
    "    seed_nodes_in_graph = [x for x in seed_nodes if x in g]\n",
    "    if len(seed_nodes_in_graph)==0:\n",
    "        return -2\n",
    "    for remaining_seed in seed_nodes_in_graph:\n",
    "        removed_seed_edges = g.edges([x for x in seed_nodes if x!= remaining_seed])\n",
    "        h = nx.DiGraph(g)\n",
    "        h.remove_edges_from(removed_seed_edges)\n",
    "        if remaining_seed in h and nx.has_path(h,source_seed,remaining_seed):\n",
    "            test_minimum_path.append( len(nx.shortest_path(h,source_seed,remaining_seed)) )\n",
    "        #g.add_edges_from(removed_seed_edges)\n",
    "    if test_minimum_path==[]:\n",
    "        return -1\n",
    "    else: \n",
    "        return min(test_minimum_path)\n",
    "    \n",
    "def transposeDict(original_dict,items=False):\n",
    "    result = defaultdict(list)\n",
    "    items_l = original_dict.items() if not items else original_dict\n",
    "    for k,v in items_l:\n",
    "        result[v].append(k)\n",
    "    result = dict(result)\n",
    "    return result\n",
    "\n",
    "def incrementWeights(partition_transpose,g_temp,is_ig=False): #CHANGE THIS TO ACTUALLY BE RIGHT\n",
    "    if is_ig:\n",
    "        g_ig_lookup_table_rev = transposeDict(g_ig_lookup_table)\n",
    "        for thing in partition_transpose:\n",
    "            partition_transpose[thing] = set([g_ig_lookup_table_rev[x][0] for x in partition_transpose[thing]])\n",
    "    for comm in partition_transpose:\n",
    "        for e1,e2 in combinations(partition_transpose[comm],2):\n",
    "            if g_temp.has_edge(e1,e2):\n",
    "                g_temp[e1][e2]['weight'] += 1\n",
    "#             else:\n",
    "#                 g.add_edge(e1,e2,attr_dict={'weight':1})\n",
    "    return g_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics of interest\n",
    "* Shortest path to seeds\n",
    "* Distribution of people in k-shells over time\n",
    "* Communities and their membership over time\n",
    "* Figure out centrality distribution for evenness. Are bots really high?\n",
    "\n",
    "Use LaNet-Vi to visualize k-core\n",
    "How do check for number of overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node statistics - Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#k_core values\n",
    "k_core = nx.core_number(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 102/53133 [02:24<20:55:37,  1.42s/it]"
     ]
    },
    {
     "ename": "NetworkXError",
     "evalue": "Input is not a correct NetworkX graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/convert.py\u001b[0m in \u001b[0;36mto_networkx_graph\u001b[0;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m     94\u001b[0m                                         \u001b[0mcreate_using\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_using\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                                         multigraph_input=data.is_multigraph())\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'graph'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# data.graph should be dict-like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/convert.py\u001b[0m in \u001b[0;36mfrom_dict_of_dicts\u001b[0;34m(d, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m    358\u001b[0m             G.add_edges_from(((u, v, data)\n\u001b[0;32m--> 359\u001b[0;31m                               \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                               for v, data in nbrs.items()))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dc2abcdb4d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mshortest_paths_2_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mshortest_paths_2_seeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshortestPath2Seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-208f8daba2bc>\u001b[0m in \u001b[0;36mshortestPath2Seeds\u001b[0;34m(source_seed, seed_nodes, g)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mremaining_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_nodes_in_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mremoved_seed_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m!=\u001b[0m \u001b[0mremaining_seed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremoved_seed_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremaining_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msource_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mremaining_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, incoming_graph_data, **attr)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# attempt to load graph with data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mincoming_graph_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_networkx_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming_graph_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_using\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;31m# load graph attributes (must be after convert)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/networkx/convert.py\u001b[0m in \u001b[0;36mto_networkx_graph\u001b[0;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input is not a correct NetworkX graph.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# pygraphviz  agraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNetworkXError\u001b[0m: Input is not a correct NetworkX graph."
     ]
    }
   ],
   "source": [
    "shortest_paths_2_seeds = {}\n",
    "for node in tqdm(g):\n",
    "    shortest_paths_2_seeds[node] = shortestPath2Seeds(node,seed_nodes,g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection - Single\n",
    "\n",
    "In this section, I'm going evaluate the communities on the dynamic RT/MN networks to track the emergence and evolution of communities in the network. \n",
    "\n",
    "I implement the _consensus clustering_ method outlined in Lancichinetti & Fortunato's paper (2012) with application to dynamic networks as outlined in Fortunato (2016). Consensus clustering is basically running many community detection methods and then weighting the edges of the network with the mutual pairs in each community detection result. Then run a weighted community detection method on the weighted graph. For the dynamic networks, I'm going to use the Hungarian algorithm for the assignment problem of matching communities across moving bins that minimize the Jaccard distances between community membership. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                 | My ideas      | Learned from Santo |\n",
    "|-----------------|---------------|--------------------|\n",
    "| Partition Type  | Community     | Cover              |\n",
    "| Distance metric | Jaccard D     | NMI                |\n",
    "| Assignment Alg  | Min Hungarian | Pick best?         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic parameters\n",
    "g_consensus_cluster = nx.Graph(g)\n",
    "#Add edge attributes\n",
    "nx.set_edge_attributes(g_consensus_cluster,name='weight',values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual community assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Communities over time - Using consensus clustering\n",
    "#Louvain community\n",
    "partition_lou = comm2.best_partition(nx.Graph(g))\n",
    "partition_lou_transpose = transposeDict(partition_lou)\n",
    "#Push to original graph\n",
    "g_consensus_cluster = incrementWeights(partition_lou_transpose,g_consensus_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Infomap\n",
    "partition_info = g_ig.community_infomap(trials=20)\n",
    "partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_info.membership)\n",
    "partition_info_transpose = transposeDict(partition_memberships,items=True)\n",
    "#Push to original graph\n",
    "g_consensus_cluster = incrementWeights(partition_info_transpose,g_consensus_cluster,is_ig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Label propogation method\n",
    "#comm1.label_propagation_communities(g) #networkx implementation, doesn't seem to work\n",
    "partition_label = g_ig.community_label_propagation()\n",
    "partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_label.membership)\n",
    "partition_label_transpose = transposeDict(partition_memberships,items=True)\n",
    "#Push to original graph\n",
    "g_consensus_cluster = incrementWeights(partition_label_transpose,g_consensus_cluster,is_ig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consensus cluster community assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Louvain\n",
    "partition_f = comm2.best_partition(g_consensus_cluster, weight='weight')\n",
    "partition_f_transpose = transposeDict(partition_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this for all networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in tqdm(os.listdir(networks_folder)):\n",
    "    with open(networks_folder+filename) as f:\n",
    "        g = pickle.load(f)\n",
    "    k_core = nx.core_number(g)\n",
    "    shortest_paths_2_seeds = {}\n",
    "    for node in tqdm(g):\n",
    "        shortest_paths_2_seeds[node] = shortestPath2Seeds(node,seed_nodes,g)\n",
    "    \n",
    "    #Creating igraph\n",
    "    g_ig_lookup_table = {}\n",
    "    counter = 0\n",
    "    for node in g:\n",
    "        g_ig_lookup_table[node] = counter\n",
    "        counter += 1\n",
    "    g_ig = ig.Graph(len(g), [(g_ig_lookup_table[x],g_ig_lookup_table[y]) for x,y in list(g.edges()) if y!='None'])\n",
    "    #Creating consensus cluster\n",
    "    g_consensus_cluster = nx.Graph(g)\n",
    "    nx.set_edge_attributes(g_consensus_cluster,name='weight',values=0)\n",
    "    \n",
    "    #Communities over time - Using consensus clustering\n",
    "    #Louvain community\n",
    "    partition_lou = comm2.best_partition(nx.Graph(g))\n",
    "    partition_lou_transpose = transposeDict(partition_lou)\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_lou_transpose,g_consensus_cluster)\n",
    "\n",
    "    #Infomap\n",
    "    partition_info = g_ig.community_infomap(trials=20)\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_info.membership)\n",
    "    partition_info_transpose = transposeDict(partition_memberships,items=True)\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_info_transpose,g_consensus_cluster,is_ig=True)\n",
    "\n",
    "    #Label propogation method\n",
    "    #comm1.label_propagation_communities(g) #networkx implementation, doesn't seem to work\n",
    "    partition_label = g_ig.community_label_propagation()\n",
    "    partition_memberships = zip([g_ig.vs[x].index for x in range(g_ig.vcount())], partition_label.membership)\n",
    "    partition_label_transpose = transposeDict(partition_memberships,items=True)\n",
    "    #Push to original graph\n",
    "    g_consensus_cluster = incrementWeights(partition_label_transpose,g_consensus_cluster,is_ig=True)\n",
    "    \n",
    "    #Final community assignment\n",
    "    partition_f = comm2.best_partition(g_consensus_cluster, weight='weight')\n",
    "    \n",
    "    df = pd.DataFrame([k_core,shortest_paths_2_seeds,partition_f]).T.rename(index=str,columns={0:\"k_value\",1:\"SP2S\",2:\"Community\"})\n",
    "    with open(nodestats_folder+filename) as f:\n",
    "        df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
